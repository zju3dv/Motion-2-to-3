{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d import os_chdir_to_proj_root\n",
    "\n",
    "os_chdir_to_proj_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2645068/3271024438.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hml3d_joints = torch.load(\"./inputs/hml3d/joints3d.pth\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from hmr4d.utils.smplx_utils import make_smplx\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines\n",
    "from hmr4d.utils.geo_transform import apply_T_on_points, compute_T_ayfz2ay\n",
    "from hmr4d.utils.camera_utils import get_camera_mat_zface, cartesian_to_spherical\n",
    "import hmr4d.utils.matrix as matrix\n",
    "\n",
    "hml3d_joints = torch.load(\"./inputs/hml3d/joints3d.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs/amass/smplhg_raw/EKUT/300/PushBeamPedar_13_poses.npz\n"
     ]
    }
   ],
   "source": [
    "all_keys = list(hml3d_joints.keys())\n",
    "idx = 300\n",
    "print(hml3d_joints[all_keys[idx]][\"name\"])\n",
    "\n",
    "DISTANCE = 4.5\n",
    "MAX_ANGLE = 180\n",
    "ELEVA_ANGLE = 5\n",
    "N_VIEWS = 4\n",
    "\n",
    "\n",
    "def get_j3d_T_w2c(k):\n",
    "    joints_pos = hml3d_joints[k][\"joints3d\"]\n",
    "    joints_pos = torch.tensor(joints_pos, dtype=torch.float32)\n",
    "    T_ay2ayfz = compute_T_ayfz2ay(joints_pos[:1], inverse=True)[0]  # (4, 4)\n",
    "    joints_pos = apply_T_on_points(joints_pos, T_ay2ayfz)\n",
    "    root_pos = joints_pos[:, :1]  # (F, 1, 3)\n",
    "    root_next = joints_pos[1:, :1]  # (F - 1, 1, 3)\n",
    "    root_next = torch.cat([root_next, root_next[-1:]], dim=0)  # (F, 1, 3)\n",
    "    joints_pos = torch.cat([joints_pos, root_next], dim=-2)  # (F, 23, 3)\n",
    "    F, J, _ = joints_pos.shape\n",
    "\n",
    "    distance = torch.ones((N_VIEWS,)) * DISTANCE\n",
    "    max_angle = MAX_ANGLE / 180 * torch.pi\n",
    "    start = torch.rand((1,)) * 2 * torch.pi\n",
    "    interval = 2 * max_angle / N_VIEWS\n",
    "    angle = [start + i * interval for i in range(N_VIEWS)]\n",
    "    angle = torch.cat((angle), dim=-1)\n",
    "    eleva_angle = torch.ones((N_VIEWS,)) * ELEVA_ANGLE / 180.0 * torch.pi\n",
    "    cam_mat = get_camera_mat_zface(matrix.identity_mat()[None], distance, angle, eleva_angle)  # N, 4, 4\n",
    "    cam_mat = cam_mat[None].expand(F, -1, -1, -1)  # (F, N, 4, 4)\n",
    "    cam_mat = matrix.set_position(cam_mat, matrix.get_position(cam_mat) + root_pos)  # (F, N, 4, 4)\n",
    "    T_w2c = torch.inverse(cam_mat)  # F, N, 4, 4\n",
    "\n",
    "    return joints_pos, T_w2c\n",
    "\n",
    "\n",
    "joints_pos, T_w2c = get_j3d_T_w2c(all_keys[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1920x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_ids = [20, 50, 80]\n",
    "\n",
    "j3d_selected = joints_pos[frame_ids]\n",
    "T_w2c_selected = T_w2c[frame_ids]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from hmr4d.utils.geo_transform import project_p2d, apply_T_on_points\n",
    "from hmr4d.utils.wis3d_utils import KINEMATIC_CHAINS, get_const_colors, color_schemes, add_motion_as_lines\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_2d_skeleton(j3d_frame1_cam, save_path=None, rgb_color=None):\n",
    "    assert rgb_color is not None\n",
    "    size = 400\n",
    "    f = 900\n",
    "    K = torch.tensor([[f, 0, size / 2], [0, f, size / 2], [0, 0, 1]])\n",
    "    f2d_frame1_cam = project_p2d(j3d_frame1_cam, K, size)\n",
    "    f2d_frame1_cam = f2d_frame1_cam.detach().cpu().numpy()[:22, :]\n",
    "\n",
    "    plt.gca().set_facecolor((0, 0, 0, 0))\n",
    "    # Plot lines\n",
    "    kinematic_chain = KINEMATIC_CHAINS[\"smpl22\"]\n",
    "    for chain in kinematic_chain:\n",
    "        for i in range(len(chain) - 1):\n",
    "            x1, y1 = f2d_frame1_cam[chain[i]]\n",
    "            x2, y2 = f2d_frame1_cam[chain[i + 1]]\n",
    "            plt.plot([x1, x2], [y1, y2], \"-\", color=rgb_color, linewidth=7, solid_capstyle='round')\n",
    "\n",
    "    # # plot circle\n",
    "    # for i in range(f2d_frame1_cam.shape[0]):\n",
    "    #     x, y = f2d_frame1_cam[i]\n",
    "    #     # plt.plot(x, y, \"o\", markersize=10, markerfacecolor=[1, 1, 1], markeredgecolor=rgb_color, markeredgewidth=3)  # 空心圆，边缘有颜色\n",
    "    #     plt.plot(x, y, \".\", markersize=10, markerfacecolor=[1, 1, 1], markeredgecolor=rgb_color, markeredgewidth=3)  # 空心圆，边缘有颜色\n",
    "\n",
    "    plt.xlim(0, size)\n",
    "    plt.ylim(0, size)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gcf().set_dpi(300)  # 设置dpi高一些\n",
    "    plt.axis(\"off\")  # 关闭坐标轴\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, format=\"png\", bbox_inches=\"tight\", pad_inches=0, dpi=300, transparent=True)\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "# rgb_start_end = [[56, 239, 125], [17, 153, 142]]\n",
    "# rgb_start_end = [[149, 215, 213], [74, 194, 154]]\n",
    "\n",
    "rgb_start_end = [[125, 223, 215], [24, 96, 90]]\n",
    "n_colors = 3\n",
    "rgb_colors = [\n",
    "    [int(rgb_start_end[0][i] + (rgb_start_end[1][i] - rgb_start_end[0][i]) * t / n_colors) for i in range(3)]\n",
    "    for t in range(n_colors)\n",
    "]\n",
    "\n",
    "output_dir = Path(\"./outputs/figure/teaser_local_vel_v1\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "png_paths = []\n",
    "for idx in range(len(frame_ids)):\n",
    "    for i in range(1):\n",
    "        rgb_color = [n / 255 for n in rgb_colors[idx]]\n",
    "        j3d_frame1_cam = apply_T_on_points(j3d_selected[idx], T_w2c_selected[idx][i])\n",
    "        save_path = output_dir / f\"2d_skeleton_frame{idx}_{i}.png\"\n",
    "        png_paths.append(save_path)\n",
    "        draw_2d_skeleton(j3d_frame1_cam, save_path, rgb_color)\n",
    "\n",
    "# Merge pngs in a row\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "pngs = [cv2.imread(png_path) for png_path in png_paths]\n",
    "pngs = np.concatenate(pngs, axis=1)\n",
    "cv2.imwrite(output_dir / \"2d_skeleton.png\", pngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "render2d3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
