{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Wis3D\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d, get_gradient_colors, get_const_colors\n",
    "wis3d = make_wis3d(name=\"triangulation\", time_postfix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMASS: orthogonal + control 1 view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['length', 'bbxs_lurb', 'bi01_motion2ds', 'gt_w_motion', 'Ts_w2c', 'is_pinhole', 'Ks'])\n",
      "length: torch.Size([4])\n",
      "bbxs_lurb: torch.Size([4, 5, 4])\n",
      "bi01_motion2ds: torch.Size([4, 5, 120, 22, 2])\n",
      "gt_w_motion: torch.Size([4, 120, 22, 3])\n",
      "Ts_w2c: torch.Size([4, 5, 4, 4])\n",
      "is_pinhole: torch.Size([4])\n",
      "Ks: torch.Size([4, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Read from RICH dataset. To form an example data.\n",
    "from hmr4d.dataset.amass.amass_motion_multiview import Dataset\n",
    "\n",
    "cfg_ = {\"root\": \"inputs/amass/smplh_joints3d.pth\", \"is_pinhole\": False, \"is_uniform\": False}\n",
    "dataloader = torch.utils.data.DataLoader(Dataset(**cfg_), batch_size=4, shuffle=False, num_workers=0)\n",
    "dataloader_iter = iter(dataloader)\n",
    "batch = next(dataloader_iter)\n",
    "print(batch.keys())\n",
    "\n",
    "for k in batch.keys():\n",
    "    print(f\"{k}: {batch[k].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat, einsum\n",
    "from hmr4d.utils.geo_transform import apply_T_on_points, project_p2d\n",
    "\n",
    "Ts_w2c = batch[\"Ts_w2c\"]  # (B, V=5, 4, 4)\n",
    "V = Ts_w2c.shape[1]\n",
    "\n",
    "# Get c_p2d (B, V, N, 2)\n",
    "w_p3d = batch[\"gt_w_motion\"][:, 0, :, :]  # (B, N=23, 3)\n",
    "c_p3d = rearrange(\n",
    "    apply_T_on_points(repeat(w_p3d, \"b n c -> (b v) n c\", v=V), rearrange(Ts_w2c, \"b v c d -> (b v) c d\")),\n",
    "    \"(b v) n c -> b v n c\",\n",
    "    v=V,\n",
    ")  # (B, V=5, N, 3)\n",
    "c_p2d = c_p3d[:, :, :, :2]  # simple orthognal projection (B, V, N, 2)\n",
    "\n",
    "# from hmr4d.utils.geo_transform import triangulate_point_ortho\n",
    "# w_p3d_  = triangulate_point_ortho(Ts_w2c, c_p2d)\n",
    "# print(f\"Error: {torch.norm(w_p3d - w_p3d_, dim=-1).mean()}\")  # -> 4.408202514127879e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 4.408202514127879e-08\n"
     ]
    }
   ],
   "source": [
    "from hmr4d.utils.geo.triangulation import triangulate_ortho_c1v\n",
    "w_p3d_triangulated = triangulate_ortho_c1v(Ts_w2c, c_p2d, controled_viewid=0)  # B, N, 3\n",
    "print(f\"Error: {torch.norm(w_p3d - w_p3d_, dim=-1).mean()}\")  # -> 4.408202514127879e-08\n",
    "\n",
    "b_vis = 3\n",
    "# Vis prediction\n",
    "colors = get_const_colors(\"red\", (w_p3d.shape[1],))\n",
    "wis3d.add_point_cloud(w_p3d_triangulated[b_vis], colors=colors, name=\"w_p3d_triangulated\")\n",
    "\n",
    "# Vis gt\n",
    "colors = get_const_colors(\"green\", (w_p3d.shape[1],))\n",
    "wis3d.add_point_cloud(w_p3d[b_vis], colors=colors, name=\"w_p3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RICH: perspective triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['length', 'gt_w_motion', 'Ts_w2c', 'Ks', 'bbxs_lurb', 'bi01_motion2ds'])\n"
     ]
    }
   ],
   "source": [
    "# Read from RICH dataset. To form an example data.\n",
    "from hmr4d.dataset.rich.rich_motion_multiview import Dataset\n",
    "dataset = Dataset()\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=False, num_workers=0)\n",
    "dataloader_iter = iter(dataloader)\n",
    "batch = next(dataloader_iter)\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.utils.wis3d_utils import add_one_joints22_as_lines\n",
    "\n",
    "# Use the first frame in the batch to examine the triangulation.\n",
    "gt_w_p3d = batch['gt_w_motion'][0, 0, :, :]  # (22, 3)\n",
    "colors = get_const_colors(\"green\", (gt_w_p3d.shape[0],))\n",
    "wis3d.add_point_cloud(gt_w_p3d, colors=colors, name='gt_w_p3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0334)\n"
     ]
    }
   ],
   "source": [
    "# Compute the projected points in each view.\n",
    "from hmr4d.utils.geo_transform import apply_T_on_points, triangulate_point\n",
    "\n",
    "c_p2d = []  # observed\n",
    "for v in range(3):\n",
    "    gt_w_p3d = batch['gt_w_motion'][:, 0, :, :]  # (B=1, 22, 3)\n",
    "    gt_c_p3d = apply_T_on_points(gt_w_p3d, batch['Ts_w2c'][:, v])  # (B, 22, 3)\n",
    "    gt_c_p2d = gt_c_p3d[..., :2] / gt_c_p3d[..., [2]]  # (B, 22, 2)\n",
    "    c_p2d.append(gt_c_p2d)\n",
    "c_p2d = torch.stack(c_p2d, dim=1)  # (B, V, 22, 2)\n",
    "\n",
    "# Add noise to c_p2d\n",
    "noise = torch.randn_like(c_p2d) * 0.01\n",
    "c_p2d += noise\n",
    "\n",
    "# Visualize\n",
    "# for v in range(3):\n",
    "#     c_p2d_ = c_p2d[0, v, :, :]  # (22, 2)\n",
    "#     c_p3d_ = F.pad(c_p2d_, (0, 1), value=1)  # (22, 3)\n",
    "#     add_one_joints22_as_lines(c_p3d_, wis3d, name=f'gt_c_p2d_{v}')\n",
    "\n",
    "# Triangulate\n",
    "w_p3d = triangulate_point(batch[\"Ts_w2c\"], c_p2d)  # (B, N, 3)\n",
    "error = torch.linalg.norm(w_p3d - batch[\"gt_w_motion\"][:, 0, :, :3], dim=2).mean()\n",
    "print(error)\n",
    "\n",
    "# Add predicted point to wis3d\n",
    "colors = get_const_colors(\"red\", (w_p3d.shape[1],))\n",
    "wis3d.add_point_cloud(w_p3d[0], colors=colors, name=\"w_p3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmr4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
