{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "from hydra import initialize_config_module, compose\n",
    "with initialize_config_module(version_base=\"1.3\", config_module=f\"hmr4d.configs\"):\n",
    "    # overrides = ['exp=mas/rpd/default', f'ckpt_path=outputs/rich_motion2d/default/checkpoints/e029-s016800.ckpt', \"ckpt_type=pl\"]\n",
    "    # overrides = ['exp=mas/rpd/amass', f'ckpt_path=outputs/amass_motion2d/default/checkpoints/e019-s161680.ckpt', \"ckpt_type=pl\"]\n",
    "    # overrides = ['exp=mas/rpd/hml', f'ckpt_path=inputs/checkpoints/mas/hml3d_mdm_transl_s589560.ckpt', \"ckpt_type=pl\"]\n",
    "    overrides = ['exp=mas/rpd/hml', f'ckpt_path=inputs/checkpoints/mas/hml3d_mdm_e0541-s221136.ckpt', \"ckpt_type=pl\", \"model.network.args.stats_name=HML3D_ORTHO\"]\n",
    "\n",
    "    overrides += [\"model.network.args_clip.clip_pretrained_path=inputs/checkpoints/huggingface/clip-vit-base-patch32\"]    \n",
    "    cfg = compose(config_name='train', overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "from hmr4d.utils.net_utils import load_pretrained_model\n",
    "\n",
    "model = instantiate(cfg.model, _recursive_=False)\n",
    "load_pretrained_model(model, cfg.ckpt_path, cfg.ckpt_type)\n",
    "model = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmr4d.utils.matrix as matrix\n",
    "from hmr4d.utils.camera_utils import get_camera_mat_zface\n",
    "distance = torch.ones((1,))\n",
    "angle = torch.rand((1,)) * 2 * torch.pi\n",
    "cam_mat = get_camera_mat_zface(matrix.identity_mat()[None], distance, angle)  # 1, 4, 4\n",
    "T_w2c = torch.inverse(cam_mat)[0]  # 4, 4\n",
    "\n",
    "batch = {\n",
    "    \"length\": 120,  # Value = F\n",
    "    \"bbx_lurb\": torch.tensor([0, 0, 1, 1], dtype=torch.float32),  # (F, 4)\n",
    "    # \"gt_bi01_motion2d\": bi01_motion2d.float(),  # (F, 22, 2)\n",
    "    # \"gt_motion\": joints_pos.float(),  # (F, 22, 3)\n",
    "    \"text\": \"running to left\",\n",
    "    # \"text\": \"\",\n",
    "    \"Ts_w2c\": T_w2c.float()[None],  # (1, 4, 4)\n",
    "    \"is_pinhole\": False,  # Value = False or True\n",
    "}\n",
    "from torch.utils.data import default_collate\n",
    "batch = default_collate([batch] * 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in batch.items() }\n",
    "\n",
    "model.generate_target = \"forward_sample\"\n",
    "outputs = model.validation_step(batch, 0)\n",
    "print(outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.utils.wis3d_utils import make_wis3d, get_gradient_colors, get_const_colors, add_joints22_motion_as_lines\n",
    "wis3d = make_wis3d(name=\"hml_model\", time_postfix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bi01_motion2d = outputs['pred_bi01_motion2d'].detach()  # (B, L, J, 2)\n",
    "pred_pseudo_motion3d = F.pad(pred_bi01_motion2d, (0, 1), value=0)\n",
    "for b in range(8):\n",
    "    add_joints22_motion_as_lines(pred_pseudo_motion3d[b], wis3d, name=f'sample{b:02d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = instantiate(cfg.data)\n",
    "dataloader = datamodule.train_dataloader()\n",
    "dataloader = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = dataloader.next()\n",
    "print(batch.keys())\n",
    "outputs = model.validation_step(batch, 0)\n",
    "print(outputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.utils.wis3d_utils import make_wis3d, get_gradient_colors, get_const_colors, add_joints22_motion_as_lines\n",
    "wis3d = make_wis3d(name=\"uncond2d\", time_postfix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bi01_motion2d = outputs['pred_bi01_motion2d'].detach()  # (B, L, J, 2)\n",
    "pred_pseudo_motion3d = F.pad(pred_bi01_motion2d, (0, 1), value=0)\n",
    "for b in range(4):\n",
    "    add_joints22_motion_as_lines(pred_pseudo_motion3d[b], wis3d, name=f'sample{b:02d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(outputs, \"tmp_outputs_4bs.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmr4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
