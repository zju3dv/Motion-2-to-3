{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d import os_chdir_to_proj_root\n",
    "\n",
    "os_chdir_to_proj_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines\n",
    "\n",
    "mdm_results_root = Path(\"inputs/mdm_results\")\n",
    "dataname_to_mdm_results = {\n",
    "    \"hml3d\": np.load(mdm_results_root / \"seed10_omg_hml3d/results.npy\", allow_pickle=True).item(),\n",
    "    \"mixamo\": np.load(mdm_results_root / \"seed10_omg_mixamo/results.npy\", allow_pickle=True).item(),\n",
    "    \"mtx\": np.load(mdm_results_root / \"seed10_omg_mtx/results.npy\", allow_pickle=True).item(),\n",
    "    \"egoexo_release\": np.load(mdm_results_root / \"seed10_sample_egoexo_100v2/results.npy\", allow_pickle=True).item(),\n",
    "    \"egoexo_gpt\": np.load(mdm_results_root / \"seed10_sample_gpt_egoexo_100v2_2/results.npy\", allow_pickle=True).item(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== hml3d ====================\n",
      "['motion', 'text', 'lengths', 'num_samples', 'num_repetitions']\n",
      "57 Motions = 19 samples x 3 repetitions\n",
      "lenths set: {140}\n",
      "All texts:\n",
      "==================== mixamo ====================\n",
      "['motion', 'text', 'lengths', 'num_samples', 'num_repetitions']\n",
      "54 Motions = 18 samples x 3 repetitions\n",
      "lenths set: {140}\n",
      "All texts:\n",
      "==================== mtx ====================\n",
      "['motion', 'text', 'lengths', 'num_samples', 'num_repetitions']\n",
      "54 Motions = 18 samples x 3 repetitions\n",
      "lenths set: {140}\n",
      "All texts:\n",
      "==================== egoexo_release ====================\n",
      "['motion', 'text', 'lengths', 'num_samples', 'num_repetitions']\n",
      "144 Motions = 48 samples x 3 repetitions\n",
      "lenths set: {140}\n",
      "All texts:\n",
      "==================== egoexo_gpt ====================\n",
      "['motion', 'text', 'lengths', 'num_samples', 'num_repetitions']\n",
      "144 Motions = 48 samples x 3 repetitions\n",
      "lenths set: {140}\n",
      "All texts:\n"
     ]
    }
   ],
   "source": [
    "def print_info(result, name):\n",
    "    print(f\"==================== {name} ====================\")\n",
    "    print(list(result.keys()))\n",
    "    num_samples = result[\"num_samples\"]\n",
    "    num_repetitions = result[\"num_repetitions\"]\n",
    "    num_motions = len(result[\"motion\"])\n",
    "    assert num_motions == num_samples * num_repetitions\n",
    "    print(f\"{num_motions} Motions = {num_samples} samples x {num_repetitions} repetitions\")\n",
    "    print(f\"lenths set:\", set(result[\"lengths\"]))\n",
    "    # text_lines = \"\\n\".join([f\"{i:2d}: {t}\" for i, t in enumerate(sorted(set(result[\"text\"])))])\n",
    "    text_lines = \"\\n\".join([f\"{t}\" for i, t in enumerate(sorted(set(result[\"text\"])))])\n",
    "    print(f\"All texts:\")\n",
    "    # print(f\"{text_lines}\")\n",
    "\n",
    "\n",
    "for dataname, results in dataname_to_mdm_results.items():\n",
    "    print_info(results, dataname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 212.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from hmr4d.dataset.HumanML3D.utils import resample_motion_fps\n",
    "import torch\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataname_to_text_info = {}\n",
    "\n",
    "for dataname, result in tqdm(dataname_to_mdm_results.items()):\n",
    "    # result = dataname_to_mdm_results[\"hml3d\"]\n",
    "    # text = result[\"text\"]  # N*3\n",
    "    # motion = result[\"motion\"]  # N*3*196\n",
    "    length = result[\"lengths\"]  # N\n",
    "    assert set(length) == {140}\n",
    "    text_to_textid = {text: idx for idx, text in enumerate(sorted(set(result[\"text\"])))}\n",
    "    textid_to_text = {v: k for k, v in text_to_textid.items()}\n",
    "    textid_to_motions = defaultdict(list)\n",
    "    for text, motion in zip(result[\"text\"], result[\"motion\"]):\n",
    "        textid = text_to_textid[text]\n",
    "        # Clip to 140 frames and upsample from 20fps to 30fps\n",
    "        motion = motion.transpose(2, 0, 1)[:140]\n",
    "        larget_length = torch.tensor(140 / 20 * 30).long()\n",
    "        motion = resample_motion_fps(torch.from_numpy(motion), larget_length).numpy()\n",
    "        textid_to_motions[textid].append(motion)  # (F, 22, 3)\n",
    "\n",
    "    # Add to dataname_to_text_info\n",
    "    dataname_to_text_info[dataname] = {\"textid_to_text\": textid_to_text, \"text_to_textid\": text_to_textid}\n",
    "\n",
    "    if False:\n",
    "        # Add results:\n",
    "        for idx in textid_to_motions:\n",
    "            motions = textid_to_motions[idx]\n",
    "            text = textid_to_text[idx]\n",
    "\n",
    "            wis3d_scene_name = f\"{dataname}@{idx:03d}@{text}\"\n",
    "            wis3d = make_wis3d(output_dir=\"outputs/wis3d_compare_mdm_ours\", name=wis3d_scene_name)\n",
    "            for i, motion in enumerate(motions):\n",
    "                # Adding a offset\n",
    "                motion_ = (motion + (i + 1) * np.array([1.0, 0.0, 0.0])).astype(np.float32)\n",
    "                add_motion_as_lines(motion_, wis3d, name=f\"mdm#{i}\", const_color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "all_text = []\n",
    "for dataname, text_info in dataname_to_text_info.items():\n",
    "    all_text.extend(list(text_info[\"textid_to_text\"].values()))\n",
    "print(len(all_text))\n",
    "print(len(set(all_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d, add_motion_as_lines\n",
    "\n",
    "ours_results_root = Path(\"inputs/ours_results/1008_compare3\")\n",
    "if False:  # convert dump_results to np_file\n",
    "    dataname_to_rawdir = {\n",
    "        \"ours_mdm_frompred_hml4x\": \"outputs/dumped/mdm_frompred_hml4x\",\n",
    "        \"ours_mdm_frompred\": \"outputs/dumped/mdm_frompred\",\n",
    "        \"ours_mdm_frompred_onlyhml\": \"outputs/dumped/mdm_frompred_onlyhml\",\n",
    "    }\n",
    "    for dataname, rawdir in dataname_to_rawdir.items():\n",
    "        results = [torch.load(p) for p in Path(rawdir).glob(\"*.pth\")]\n",
    "        torch.save(results, ours_results_root / f\"{dataname}.pt\")\n",
    "\n",
    "ours_results = {\n",
    "    \"ours_mdm_frompred_onlyhml\": torch.load(ours_results_root / \"ours_mdm_frompred_onlyhml.pt\"),\n",
    "    \"ours_mdm_frompred_hml4x\": torch.load(ours_results_root / \"ours_mdm_frompred_hml4x.pt\"),\n",
    "    \"ours_mdm_frompred\": torch.load(ours_results_root / \"ours_mdm_frompred.pt\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [00:32<00:00,  4.69it/s]\n",
      "100%|██████████| 151/151 [00:33<00:00,  4.52it/s]\n",
      "100%|██████████| 151/151 [00:33<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "ours_offsets = {\n",
    "    \"ours_mdm_frompred_onlyhml\": torch.tensor([0, 0, 0]),\n",
    "    \"ours_mdm_frompred_hml4x\": torch.tensor([-1, 0, 0]),\n",
    "    \"ours_mdm_frompred\": torch.tensor([-2, 0, 0]),\n",
    "}\n",
    "\n",
    "\n",
    "# LOOK-UP INDEX\n",
    "text_to_dataname_idx = {}\n",
    "for dataname, text_info in dataname_to_text_info.items():\n",
    "    for text, textid in text_info[\"text_to_textid\"].items():\n",
    "        text_to_dataname_idx[text] = (dataname, textid)\n",
    "\n",
    "for method_name in ours_results:\n",
    "    # method_name = \"ours_mdm_frompred_hml4x\"\n",
    "    color = \"blue\"\n",
    "\n",
    "    results = ours_results[method_name]\n",
    "    for result in tqdm(results):\n",
    "        # result = results[1]  # ['pred', 'text', 'length']\n",
    "        pred = result[\"pred\"]\n",
    "        text = result[\"text\"]\n",
    "        dataname, idx = text_to_dataname_idx[text]\n",
    "\n",
    "        wis3d_scene_name = f\"{dataname}@{idx:03d}@{text}\"\n",
    "        wis3d = make_wis3d(output_dir=\"outputs/wis3d_compare_mdm_ours\", name=wis3d_scene_name)\n",
    "        pred_plot = pred + ours_offsets[method_name]\n",
    "        add_motion_as_lines(pred_plot, wis3d, name=method_name, const_color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m2d3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
