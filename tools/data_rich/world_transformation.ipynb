{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir('../../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d\n",
    "from hmr4d.utils.wis3d_utils import add_joints22_motion_as_lines\n",
    "from hmr4d.dataset.rich.rich_utils import get_w2az_sahmr, parse_seqname_info\n",
    "from hmr4d.utils.geo_transform import apply_T_on_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wis3d = make_wis3d(name='rich_joints3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load joints3d-motion\n",
    "rich_joints3d = np.load(\"inputs/RICH/hmr4d_support/joints3d/joints3d_smpl_v2.npy\", allow_pickle=True).item()\n",
    "rich_joints3d = {k: torch.from_numpy(v) for k, v in rich_joints3d.items()}\n",
    "# add_joints22_motion_as_lines(rich_joints3d[seq_names[20]], wis3d, \"joints22_w\")\n",
    "\n",
    "# Setup Meta for getitem(i)\n",
    "meta = []\n",
    "length = 120\n",
    "rich_fps = 30\n",
    "for seq_name in rich_joints3d.keys():\n",
    "    total_length = rich_joints3d[seq_name].shape[0]\n",
    "    # Rules: skip first 1 seconds (30frames), sample interval is 0.5 second\n",
    "    for start_frame in range(rich_fps, total_length - length, int(rich_fps*0.5)):\n",
    "        end_frame = start_frame + length\n",
    "        meta.append((seq_name, start_frame, end_frame))\n",
    "\n",
    "# Transformation\n",
    "w2az = get_w2az_sahmr()  # scan_name: tensor 4,4\n",
    "seqname_info = parse_seqname_info()\n",
    "seqname_to_scanname = {k: v[0] for k, v in seqname_info.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 42\n",
    "seq_name, start_frame, end_frame = meta[i]\n",
    "\n",
    "# Get 120 frames of motion\n",
    "motion = rich_joints3d[seq_name][start_frame:end_frame]  # (120, 22, 3)\n",
    "# add_joints22_motion_as_lines(motion, wis3d, \"sample_c1\")\n",
    "\n",
    "# Transform to az\n",
    "scan_name = seqname_to_scanname[seq_name]\n",
    "\n",
    "motion_az = apply_T_on_points(motion, w2az[scan_name][None])\n",
    "add_joints22_motion_as_lines(motion_az, wis3d, \"sample_az\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.utils.geo_transform import compute_T_ayf2az\n",
    "\n",
    "T_az2ayf = compute_T_ayf2az(motion_az[None, 0], inverse=True)[0]  # (4, 4)\n",
    "motion_ayf = apply_T_on_points(motion_az, T_az2ayf[None])  # (F, 22, 3)\n",
    "add_joints22_motion_as_lines(motion_ayf, wis3d, \"sample_ayf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Decide scene_name\n",
    "# LectureHall_chair_seqs = [  # others are LectureHall_yoga\n",
    "#     \"LectureHall_018_wipingtable1\",\n",
    "#     \"LectureHall_020_wipingchairs1\",\n",
    "#     \"LectureHall_003_wipingchairs1\",\n",
    "#     \"LectureHall_018_wipingchairs1\",\n",
    "#     \"LectureHall_018_wipingspray1\",\n",
    "#     \"LectureHall_020_wipingtable1\",\n",
    "#     \"LectureHall_019_wipingchairs1\",\n",
    "# ]\n",
    "\n",
    "# scene_name = seq_name.split(\"_\")[0]\n",
    "# if scene_name == \"LectureHall\":\n",
    "#     scene_name += \"_chair\" if seq_name in LectureHall_chair_seqs else \"_yoga\"\n",
    "\n",
    "# # Get cam2world\n",
    "# cam2world_dir = Path(\"hmr4d/dataset/rich/multicam2world\")\n",
    "# cam2scan = json.load((cam2world_dir / f\"{scene_name}_multicam2world.json\").open())\n",
    "\n",
    "# rot_mat = torch.tensor(cam2scan['R'])\n",
    "# translation = torch.tensor(cam2scan['t'])\n",
    "\n",
    "# print(motion.shape)\n",
    "# motion_align = motion @ rot_mat[None] + translation[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmr4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
