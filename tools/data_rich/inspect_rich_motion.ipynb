{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change working directory to project root\n",
    "os.chdir('../../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import imageio\n",
    "from hmr4d.utils.wis3d_utils import make_wis3d\n",
    "from hmr4d.utils.wis3d_utils import add_joints22_motion_as_lines\n",
    "from hmr4d.dataset.rich.rich_utils import get_w2az_sahmr, parse_seqname_info\n",
    "from hmr4d.utils.geo_transform import apply_T_on_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "motion_ayf = torch.zeros((120, 22, 3))  # dummy motion\n",
    "\n",
    "idx = 0\n",
    "gmpjpe, mpjpe = [], []\n",
    "for idx in range(512):\n",
    "    torch_generator = torch.Generator().manual_seed(idx)\n",
    "    cond_motion = 0.02 * torch.randn(motion_ayf.shape, generator=torch_generator) + motion_ayf.clone()\n",
    "    cond_motion = 0.15 * torch.randn(cond_motion.shape[0], generator=torch_generator)[:, None, None] + cond_motion\n",
    "\n",
    "    gmpjpe.append((cond_motion - motion_ayf).norm(dim=-1, p=2).mean(dim=-1).mean() * 1000)\n",
    "    mpjpe.append(((cond_motion - cond_motion[:, [0]]) - (motion_ayf - motion_ayf[:, [0]])).norm(dim=-1, p=2).mean()  * 1000)\n",
    "\n",
    "gmpjpe = torch.stack(gmpjpe)\n",
    "mpjpe = torch.stack(mpjpe)\n",
    "gmpjpe_cummean = gmpjpe.cumsum(dim=0) / torch.arange(1, gmpjpe.shape[0] + 1)\n",
    "mpjpe_cummean = mpjpe.cumsum(dim=0) / torch.arange(1, mpjpe.shape[0] + 1)\n",
    "# print(f'gmpjpe: {gmpjpe:.4f}, mpjpe: {mpjpe:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmpjpe_cummean = gmpjpe.cumsum(dim=0) / torch.arange(1, gmpjpe.shape[0] + 1)\n",
    "mpjpe_cummean = mpjpe.cumsum(dim=0) / torch.arange(1, mpjpe.shape[0] + 1)\n",
    "# Change to subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8))\n",
    "axs[0].plot(gmpjpe_cummean, label='gmpjpe')\n",
    "axs[1].plot(mpjpe_cummean, label='mpjpe')\n",
    "# Add titles\n",
    "axs[0].set_title('Global MPJPE')\n",
    "axs[1].set_title('MPJPE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect image clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.dataset.rich.rich_motion import Dataset\n",
    "args = {\n",
    "    \"split\": \"val\",\n",
    "    \"img_fps\": 1,  # TODO: this is semantically wrong, should be \"img_interval\"\n",
    "}\n",
    "dataset = Dataset(**args) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1010, 1014):\n",
    "    data = dataset[idx]\n",
    "    images = (data['prompt_imgs'] * 255).numpy().astype(np.uint8).transpose(0, 2, 3, 1)\n",
    "    out_fn = f\"tmp_{idx}.mp4\"\n",
    "    imageio.mimwrite(out_fn, images, fps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset (loop to see how img_interval affect the resulting video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.dataset.rich.rich_motion import Dataset\n",
    "\n",
    "out_folder = Path(\"check_invertal\")\n",
    "out_folder.mkdir(exist_ok=True)\n",
    "for interval in range(1, 30):\n",
    "    args = {\"split\":\"val\", \"img_fps\": interval}\n",
    "    dataset = Dataset(**args)\n",
    "\n",
    "    idx= 1011\n",
    "    data = dataset[idx]\n",
    "    images = (data['prompt_imgs'] * 255).numpy().astype(np.uint8).transpose(0, 2, 3, 1)\n",
    "    out_fn = out_folder / f\"{idx}_{interval}.mp4\"\n",
    "    imageio.mimwrite(out_fn, images, fps=30/interval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raw-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmr4d.dataset.rich.rich_utils import get_seqnames_of_split, get_img_fn\n",
    "split = \"val\"\n",
    "seqnames_split = get_seqnames_of_split(split)\n",
    "img_root = Path(f\"inputs/RICH/images_ds4/{split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "import imageio\n",
    "\n",
    "seqname = seqnames_split[10]\n",
    "cam_id = 0\n",
    "# Read images and dump as a video\n",
    "imgs = []\n",
    "sample_frames = 32\n",
    "for f_id in range(50, 170, int(120 / sample_frames)):\n",
    "    img_fn = get_img_fn(img_root, seqname, cam_id, f_id)\n",
    "    imgs.append(imageio.imread(img_fn))\n",
    "\n",
    "# Save as mp4 using imageio, with best quality\n",
    "out_fn = f\"tmp_{sample_frames}.mp4\"\n",
    "fps = sample_frames / 4\n",
    "imageio.mimsave(out_fn, imgs, fps=fps, quality=5)  # default=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data-range (motion and image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_joints3d = np.load(\"inputs/RICH/hmr4d_support/joints3d/joints3d_smpl_v2.npy\", allow_pickle=True).item()\n",
    "seqname2imgrange = json.load(open(\"hmr4d/dataset/rich/resource/seqname2imgrange.json\", \"r\"))\n",
    "\n",
    "# CHECK total length is equal\n",
    "for seqname in rich_joints3d:\n",
    "    joints3d = rich_joints3d[seqname][0]\n",
    "    total_length_motion = joints3d.shape[0]\n",
    "\n",
    "    total_length_img = seqname2imgrange[seqname][1] - seqname2imgrange[seqname][0] + 1\n",
    "    if total_length_motion != total_length_img:\n",
    "        print(seqname, total_length_motion, total_length_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmr4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
